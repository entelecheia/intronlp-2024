
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>4주차 세션 2 - 고급 단어 임베딩 &#8212; 언어모형과자연어처리 2024</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-examples.css?v=e236af4b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/language_selector.css?v=6a8ebae4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'week04/session2';</script>
    <script src="../_static/chat.js?v=f0de43d7"></script>
    <script src="../_static/language_switcher.js?v=730be77c"></script>
    <link rel="icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5주차 - 트랜스포머" href="../week05/index.html" />
    <link rel="prev" title="4주차 세션 1 - 단어 임베딩과 Word2Vec 소개" href="session1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <script src="/_static/language_switcher.js"></script>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-lang-select">  <nav class="menu">    <ul class="clearfix">      <li class="current-item">        <a href="#" class="clicker">          한국어 <span class="arrow">&#9660;</span>        </a>        <ul class="sub-menu">                    <li><a href="#" onclick="switchLanguage('en'); return false;">English</a></li>          <li><a href="#" onclick="switchLanguage('ko'); return false;">한국어</a></li>        </ul>      </li>    </ul>  </nav></div>
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">언어모형과자연어처리 2024</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    홈
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../week01/index.html">1주차 - 자연어처리 소개</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week01/session1.html">1주차 세션 1 - 자연어처리의 기초와 발전</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week01/session2.html">1주차 세션 2 - 현대 자연어처리의 혁명</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week01/wk1-lab1.html">1주차 실습 - 한국어 NLP 기초 소개</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week02/index.html">2주차 - 텍스트 전처리 기초</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week02/session1.html">2주차 세션 1 - 텍스트 전처리 기초</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week02/session2.html">2주차 세션 2 - 고급 텍스트 전처리 및 표현</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week02/session3.html">2주차 세션 3 - 한국어 텍스트 전처리 및 토큰화</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week03/index.html">3주차 - 언어 모델의 기초</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week03/session1.html">3주차 세션 1 - 언어 모델과 N-gram 소개</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week03/session2.html">3주차 세션 2 - 고급 통계적 언어 모델</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">4주차 - 단어 임베딩</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="session1.html">4주차 세션 1 - 단어 임베딩과 Word2Vec 소개</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">4주차 세션 2 - 고급 단어 임베딩</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week05/index.html">5주차 - 트랜스포머</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week05/session1.html">5주차 세션 1 - 트랜스포머 소개</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week05/session2.html">5주차 세션 2 - BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week05/session3.html">5주차 세션 3 - 트랜스포머의 실제 구현 및 시각화</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week06/index.html">6주차 - LLM API 이해하기</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week06/session1.html">6주차 세션 1 - LLM API 소개 및 OpenAI API 사용법</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week06/session2.html">6주차 세션 2 - 샘플링 방법과 텍스트 생성</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nobel-physics/index.html">특강 - 2024년 노벨 물리학상</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../nobel-physics/session1.html">세션 1 - 인공 신경망을 이용한 기계 학습의 기초적 발견</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nobel-physics/session2.html">세션 2 - 딥 러닝의 진화와 고급 신경망 아키텍처</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nobel-physics/session3.html">세션 3 - 인터뷰에서 얻은 깨달음</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../projects/index.html">프로젝트 가이드</a></li>
<li class="toctree-l1"><a class="reference internal" href="../projects/proposal.html">NLP 프로젝트 제안서</a></li>
<li class="toctree-l1"><a class="reference internal" href="../projects/research-note.html">[n]주차 프로젝트 연구일지</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../projects/teams.html">프로젝트 팀</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/team1/index.html">Team 1 - MakeMZ</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../projects/team1/proposal.html">NLP 프로젝트 제안서</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../projects/team1/notes.html">프로젝트 연구일지</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../projects/team1/research-note-1week-01.html">1주차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team1/research-note-2week-01.html">2주차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team1/research-note-3week-01.html">3주차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team1/research-note-4week-01.html">4주차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team1/research-note-4week-02.html">4주차 프로젝트 연구일지 -2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team1/research-note-5week-01.html">5주차 프로젝트 연구일지 -1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team1/research-note-6week-01.html">6주차 프로젝트 연구일지 -1</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/team2/index.html">Team 2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../projects/team2/proposal.html">NLP 프로젝트 제안서</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/team3/index.html">Team 3 - Nice</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../projects/team3/proposal.html">NLP 프로젝트 제안서</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../projects/team3/notes.html">프로젝트 연구일지</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../projects/team3/research-note3w.html">3주차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team3/research-note4w.html">4주차 프로젝트 연구일지</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/team4/index.html">Team 4 - 원더우먼</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../projects/team4/proposal.html">NLP 프로젝트 제안서</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../projects/team4/notes.html">프로젝트 연구일지</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../projects/team4/Research-Log/W1.html">1주차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team4/Research-Log/W2.html">2주차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team4/Research-Log/W3.html">3주차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team4/Research-Log/W4.html">4주차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team4/Research-Log/W5.html">5주차 프로젝트 연구일지</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/team5/index.html">Team 5 - AICS</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../projects/team5/proposal.html">NLP 프로젝트 제안서</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../projects/team5/notes.html">프로젝트 연구일지</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../projects/team5/research-note-1-2-3.html">1, 2, 3차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team5/research-note-4.html">4차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team5/research-note-5.html">5차 프로젝트 연구일지</a></li>
<li class="toctree-l4"><a class="reference internal" href="../projects/team5/research-note-6.html">6차 프로젝트 연구일지</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/index.html">수업계획서</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">만든 사람들</a></li>
<li class="toctree-l1"><a class="reference external" href="https://halla.ai">CHU AI Department</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/entelecheia/intronlp-2024" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/intronlp-2024/edit/main/book/ko/week04/session2.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/intronlp-2024/issues/new?title=Issue%20on%20page%20%2Fweek04/session2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/week04/session2.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>4주차 세션 2 - 고급 단어 임베딩</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glove-global-vectors-for-word-representation">1. GloVe (Global Vectors for Word Representation) 소개</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#glove">1.1 GloVe의 주요 개념</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">1.2 GloVe 알고리즘</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#python-glove">1.3 Python으로 GloVe 구현하기</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fasttext">2. FastText: 하위 단어 기반 단어 임베딩</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.1 FastText의 주요 특징</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.2 FastText 아키텍처</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gensim-fasttext">2.3 Gensim으로 FastText 구현하기</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec-glove-fasttext">3. Word2Vec, GloVe, FastText 비교</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">4. 단어 임베딩의 실제 응용</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">4.1 텍스트 분류</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ner">4.2 개체명 인식 (NER)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">5. 단어 임베딩 평가</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">5.1 내재적 평가: 단어 유사도 및 유추 작업</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">5.2 외재적 평가: 하위 작업에서의 성능</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">6. 도전 과제와 향후 방향</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">결론</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">연습 문제</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>4주차 세션 2 - 고급 단어 임베딩<a class="headerlink" href="#id1" title="Link to this heading">#</a></h1>
<section id="glove-global-vectors-for-word-representation">
<h2>1. GloVe (Global Vectors for Word Representation) 소개<a class="headerlink" href="#glove-global-vectors-for-word-representation" title="Link to this heading">#</a></h2>
<p>GloVe는 2014년 Pennington 등이 소개한 또 다른 인기 있는 단어 임베딩 기법으로, 전역 행렬 분해와 지역 문맥 윈도우 방법의 장점을 결합하는 것을 목표로 합니다.</p>
<section id="glove">
<h3>1.1 GloVe의 주요 개념<a class="headerlink" href="#glove" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>전역 단어-단어 동시 출현 통계를 활용</p></li>
<li><p>지역 및 전역 문맥을 모두 포착하는 것을 목표로 함</p></li>
<li><p>단어-단어 동시 출현 확률의 비율이 의미를 인코딩할 수 있다는 직관에 기반</p></li>
</ul>
</section>
<section id="id2">
<h3>1.2 GloVe 알고리즘<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<ol class="arabic">
<li><p>단어-단어 동시 출현 행렬 X 구성</p></li>
<li><p>목적 함수 정의:</p>
<p>J = Σᵢⱼ f(Xᵢⱼ)(wᵢᵀw̃ⱼ + bᵢ + b̃ⱼ - log Xᵢⱼ)²</p>
<p>여기서:</p>
<ul class="simple">
<li><p>wᵢ와 w̃ⱼ는 단어 벡터</p></li>
<li><p>bᵢ와 b̃ⱼ는 편향 항</p></li>
<li><p>f(Xᵢⱼ)는 가중치 함수</p></li>
</ul>
</li>
<li><p>확률적 경사 하강법을 사용하여 목적 함수 최소화</p></li>
</ol>
</section>
<section id="python-glove">
<h3>1.3 Python으로 GloVe 구현하기<a class="headerlink" href="#python-glove" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># gensim 및 GloVe 파일 다운로드</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">gensim</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">nlp</span><span class="o">.</span><span class="n">stanford</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">glove</span><span class="mf">.6</span><span class="n">B</span><span class="o">.</span><span class="n">zip</span>
<span class="err">!</span><span class="n">unzip</span> <span class="n">glove</span><span class="mf">.6</span><span class="n">B</span><span class="o">.</span><span class="n">zip</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>

<span class="c1"># GloVe 파일을 gensim 형식으로 로드 (100차원 벡터 사용)</span>
<span class="n">glove_file</span> <span class="o">=</span> <span class="s1">&#39;glove.6B.100d.txt&#39;</span>
<span class="n">glove_model</span> <span class="o">=</span> <span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="n">glove_file</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">no_header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># &#39;dog&#39;과 유사한 단어 찾기</span>
<span class="n">similar_words</span> <span class="o">=</span> <span class="n">glove_model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&#39;dog&#39;와 가장 유사한 단어들:&quot;</span><span class="p">,</span> <span class="n">similar_words</span><span class="p">)</span>

<span class="c1"># &#39;dog&#39;의 벡터 출력 (처음 5차원만 표시)</span>
<span class="n">dog_vector</span> <span class="o">=</span> <span class="n">glove_model</span><span class="p">[</span><span class="s1">&#39;dog&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&#39;dog&#39;의 벡터:&quot;</span><span class="p">,</span> <span class="n">dog_vector</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</section>
</section>
<section id="fasttext">
<h2>2. FastText: 하위 단어 기반 단어 임베딩<a class="headerlink" href="#fasttext" title="Link to this heading">#</a></h2>
<p>FastText는 2016년 Facebook Research에서 개발한 것으로, 하위 단어 정보를 포함하여 Word2Vec 모델을 확장합니다.</p>
<section id="id3">
<h3>2.1 FastText의 주요 특징<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>각 단어를 문자 n-gram의 집합으로 표현</p></li>
<li><p>어휘 외 단어에 대한 임베딩 생성 가능</p></li>
<li><p>형태학적으로 풍부한 언어에 특히 효과적</p></li>
</ul>
</section>
<section id="id4">
<h3>2.2 FastText 아키텍처<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<div class="highlight-mermaid notranslate"><div class="highlight"><pre><span></span>graph TD
    A[입력 단어] --&gt; B[문자 n-gram]
    B --&gt; C[임베딩 조회]
    C --&gt; D[합산/평균]
    D --&gt; E[단어 임베딩]
</pre></div>
</div>
</section>
<section id="gensim-fasttext">
<h3>2.3 Gensim으로 FastText 구현하기<a class="headerlink" href="#gensim-fasttext" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">FastText</span>

<span class="c1"># FastText 모델 학습</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">FastText</span><span class="p">(</span><span class="n">sentences</span><span class="o">=</span><span class="n">sentences</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># 유사한 단어 찾기</span>
<span class="n">similar_words</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s1">&#39;개&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&#39;개&#39;와 가장 유사한 단어들:&quot;</span><span class="p">,</span> <span class="n">similar_words</span><span class="p">)</span>

<span class="c1"># 어휘 외 단어에 대한 벡터 얻기</span>
<span class="n">oov_vector</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="s1">&#39;강아지&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&#39;강아지&#39;의 벡터:&quot;</span><span class="p">,</span> <span class="n">oov_vector</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>  <span class="c1"># 처음 5차원만 표시</span>

<span class="c1"># 단어 유추 수행</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;개&#39;</span><span class="p">,</span> <span class="s1">&#39;나무&#39;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;고양이&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;개 - 고양이 + 나무 =&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</section>
</section>
<section id="word2vec-glove-fasttext">
<h2>3. Word2Vec, GloVe, FastText 비교<a class="headerlink" href="#word2vec-glove-fasttext" title="Link to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>특징</p></th>
<th class="head"><p>Word2Vec</p></th>
<th class="head"><p>GloVe</p></th>
<th class="head"><p>FastText</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>학습</p></td>
<td><p>지역 문맥</p></td>
<td><p>전역 동시 출현</p></td>
<td><p>지역 문맥 + 하위 단어</p></td>
</tr>
<tr class="row-odd"><td><p>OOV 단어</p></td>
<td><p>처리 불가</p></td>
<td><p>처리 불가</p></td>
<td><p>임베딩 생성 가능</p></td>
</tr>
<tr class="row-even"><td><p>학습 속도</p></td>
<td><p>빠름</p></td>
<td><p>더 느림</p></td>
<td><p>Word2Vec과 유사</p></td>
</tr>
<tr class="row-odd"><td><p>성능</p></td>
<td><p>좋음</p></td>
<td><p>좋음</p></td>
<td><p>희귀 단어에 대해 더 나음</p></td>
</tr>
<tr class="row-even"><td><p>형태학</p></td>
<td><p>포착하지 않음</p></td>
<td><p>포착하지 않음</p></td>
<td><p>포착함</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="id5">
<h2>4. 단어 임베딩의 실제 응용<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<section id="id6">
<h3>4.1 텍스트 분류<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p>단어 임베딩은 텍스트 분류 작업의 성능을 크게 향상시킬 수 있습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># 샘플 데이터</span>
<span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;고양이와 개가 놀고 있습니다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;주식 시장이 호황입니다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;개가 고양이를 쫓고 있습니다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;투자자들이 주식을 매수하고 있습니다&quot;</span>
<span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># 0: 동물, 1: 금융</span>

<span class="c1"># 문서 임베딩을 얻는 함수 (단어 임베딩의 평균)</span>
<span class="k">def</span> <span class="nf">get_doc_embedding</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">word_vectors</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">word_vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># 데이터 준비</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">get_doc_embedding</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="c1"># 데이터 분할</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 분류기 학습</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,),</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 평가</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="ner">
<h3>4.2 개체명 인식 (NER)<a class="headerlink" href="#ner" title="Link to this heading">#</a></h3>
<p>단어 임베딩은 NER 작업의 특성으로 사용될 수 있습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">pos_tag</span><span class="p">,</span> <span class="n">ne_chunk</span>
<span class="kn">from</span> <span class="nn">nltk.chunk</span> <span class="kn">import</span> <span class="n">conlltags2tree</span><span class="p">,</span> <span class="n">tree2conlltags</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;averaged_perceptron_tagger&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;maxent_ne_chunker&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;words&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">ner_with_embeddings</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">embedding_model</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">pos_tags</span> <span class="o">=</span> <span class="n">pos_tag</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    <span class="n">ne_tree</span> <span class="o">=</span> <span class="n">ne_chunk</span><span class="p">(</span><span class="n">pos_tags</span><span class="p">)</span>
    <span class="n">iob_tags</span> <span class="o">=</span> <span class="n">tree2conlltags</span><span class="p">(</span><span class="n">ne_tree</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">iob_tags</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">embedding_model</span><span class="o">.</span><span class="n">wv</span><span class="p">:</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding_model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
            <span class="c1"># 여기서 일반적으로 임베딩을 더 정교한 NER 모델의 특성으로 사용합니다</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;단어: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">, 품사: </span><span class="si">{</span><span class="n">pos</span><span class="si">}</span><span class="s2">, NE 태그: </span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s2">, 임베딩: </span><span class="si">{</span><span class="n">embedding</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

<span class="c1"># 사용 예</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;김철수는 서울에 있는 삼성전자에서 일합니다&quot;</span>
<span class="n">ner_with_embeddings</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id7">
<h2>5. 단어 임베딩 평가<a class="headerlink" href="#id7" title="Link to this heading">#</a></h2>
<section id="id8">
<h3>5.1 내재적 평가: 단어 유사도 및 유추 작업<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate_word_similarity</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">word_pairs</span><span class="p">):</span>
    <span class="n">human_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">word_pairs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word1</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span> <span class="ow">and</span> <span class="n">word2</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">:</span>
            <span class="n">human_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">score</span><span class="p">))</span>
            <span class="n">model_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">human_scores</span><span class="p">,</span> <span class="n">model_scores</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># 인간이 할당한 유사도 점수(0-10)가 있는 예시 단어 쌍</span>
<span class="n">word_pairs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;고양이&#39;</span><span class="p">,</span> <span class="s1">&#39;개&#39;</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;자동차&#39;</span><span class="p">,</span> <span class="s1">&#39;자동차&#39;</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;책&#39;</span><span class="p">,</span> <span class="s1">&#39;종이&#39;</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;컴퓨터&#39;</span><span class="p">,</span> <span class="s1">&#39;키보드&#39;</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;달리다&#39;</span><span class="p">,</span> <span class="s1">&#39;조깅하다&#39;</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">similarity_score</span> <span class="o">=</span> <span class="n">evaluate_word_similarity</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">word_pairs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;단어 유사도 상관관계: </span><span class="si">{</span><span class="n">similarity_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id9">
<h3>5.2 외재적 평가: 하위 작업에서의 성능<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<p>감성 분석, 개체명 인식, 기계 번역과 같은 특정 NLP 작업에서의 성능을 기반으로 임베딩을 평가합니다.</p>
</section>
</section>
<section id="id10">
<h2>6. 도전 과제와 향후 방향<a class="headerlink" href="#id10" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>문맥적 임베딩</strong>: BERT와 GPT와 같은 모델은 다의어를 다루는 문맥 의존적 단어 임베딩을 생성합니다.</p></li>
<li><p><strong>다국어 임베딩</strong>: 여러 언어에서 작동하는 임베딩 생성.</p></li>
<li><p><strong>임베딩의 편향</strong>: 단어 임베딩에 존재하는 편향을 해결하고 완화.</p></li>
<li><p><strong>효율적인 학습 및 저장</strong>: 더 빠른 학습과 더 효율적인 임베딩 저장을 위한 방법 개발.</p></li>
</ol>
</section>
<section id="id11">
<h2>결론<a class="headerlink" href="#id11" title="Link to this heading">#</a></h2>
<p>GloVe와 FastText와 같은 고급 단어 임베딩 기법은 기본 Word2Vec 모델에 비해 개선을 제공하며, 특히 전역 동시 출현 통계와 하위 단어 정보 처리에서 뛰어납니다. 이러한 임베딩은 많은 NLP 작업에서 기본적인 구성 요소가 되었으며, 다양한 응용 프로그램에서 성능을 크게 향상시켰습니다.</p>
</section>
<section id="id12">
<h2>연습 문제<a class="headerlink" href="#id12" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>이전 세션에서 Word2Vec에 사용한 동일한 코퍼스에 대해 GloVe와 FastText 모델을 학습시킵니다.</p></li>
<li><p>단어 유추 작업에서 Word2Vec, GloVe, FastText의 성능을 비교합니다.</p></li>
<li><p>세 가지 임베딩 유형을 각각 사용하여 간단한 감성 분석 분류기를 구현하고 성능을 비교합니다.</p></li>
<li><p>각 모델이 어휘 외 단어를 얼마나 잘 처리하는지 분석합니다.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 여기에 코드를 작성하세요</span>
</pre></div>
</div>
<p>이 연습을 통해 다양한 단어 임베딩 기법에 대한 실제 경험을 쌓고 다양한 시나리오에서 각 기법의 장단점을 이해할 수 있습니다.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/intronlp-2024",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./week04"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
    <div class="giscus"></div>
<script src="https://giscus.app/client.js"        data-repo="entelecheia/intronlp-2024"        data-repo-id="R_kgDOMnmcQA"        data-category="General"        data-category-id="DIC_kwDOMnmcQM4Ch5PF"        data-mapping="pathname"        data-strict="1"        data-reactions-enabled="1"        data-emit-metadata="1"        data-input-position="bottom"        data-theme="noborder_light"        data-lang="ko"        data-loading="lazy"        crossorigin="anonymous"        async></script>
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="session1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">4주차 세션 1 - 단어 임베딩과 Word2Vec 소개</p>
      </div>
    </a>
    <a class="right-next"
       href="../week05/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">5주차 - 트랜스포머</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glove-global-vectors-for-word-representation">1. GloVe (Global Vectors for Word Representation) 소개</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#glove">1.1 GloVe의 주요 개념</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">1.2 GloVe 알고리즘</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#python-glove">1.3 Python으로 GloVe 구현하기</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fasttext">2. FastText: 하위 단어 기반 단어 임베딩</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.1 FastText의 주요 특징</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.2 FastText 아키텍처</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gensim-fasttext">2.3 Gensim으로 FastText 구현하기</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec-glove-fasttext">3. Word2Vec, GloVe, FastText 비교</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">4. 단어 임베딩의 실제 응용</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">4.1 텍스트 분류</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ner">4.2 개체명 인식 (NER)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">5. 단어 임베딩 평가</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">5.1 내재적 평가: 단어 유사도 및 유추 작업</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">5.2 외재적 평가: 하위 작업에서의 성능</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">6. 도전 과제와 향후 방향</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">결론</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">연습 문제</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Young Joon Lee
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
