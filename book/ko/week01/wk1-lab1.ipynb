{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1주차 실습 - 한국어 NLP 기초 소개\n",
    "\n",
    "2024년 한국어 NLP 및 LLM 입문 과정의 첫 번째 실습 세션에 오신 것을 환영합니다. 이번 실습에서는 한국어 자연어 처리(NLP)의 기본 개념을 탐구하고 몇 가지 기본적인 NLP 작업을 직접 경험해 볼 것입니다.\n",
    "\n",
    "## 목표\n",
    "\n",
    "- 한국어 NLP의 기본 개념 이해하기\n",
    "- Mecab을 사용한 토큰화 및 품사 태깅 구현하기\n",
    "- Word2Vec을 사용한 한국어 단어 임베딩 시각화하기\n",
    "- 기본적인 한국어 텍스트 생성 실험하기 (해당되는 경우)\n",
    "\n",
    "먼저 환경을 설정하고 필요한 라이브러리를 가져오겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "%pip install ekonlpy gensim matplotlib scikit-learn openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정 완료!\n"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 가져오기\n",
    "import numpy as np\n",
    "from ekonlpy import Mecab\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Mecab 초기화\n",
    "mecab = Mecab()\n",
    "\n",
    "print(\"설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 한국어 NLP 기초 소개\n",
    "\n",
    "자연어 처리(NLP)는 컴퓨터 과학, 인공지능, 언어학이 교차하는 분야입니다. 컴퓨터와 인간 언어 사이의 상호작용에 중점을 둡니다. 한국어 NLP의 주요 개념은 다음과 같습니다:\n",
    "\n",
    "- 형태소 분석: 한국어 텍스트를 의미 있는 최소 단위(형태소)로 분리하기\n",
    "- 품사 태깅: 각 형태소에 문법적 범주 할당하기\n",
    "- 개체명 인식: 텍스트에서 명명된 개체를 식별하고 분류하기\n",
    "- 단어 임베딩: 한국어 단어의 밀집 벡터 표현\n",
    "\n",
    "이러한 개념을 보여주기 위해 간단한 예제로 시작해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 텍스트: 금통위는 따라서 물가안정과 병행, 경기상황에 유의하는 금리정책을 펼쳐나가기로 했다고 밝혔다.\n"
     ]
    }
   ],
   "source": [
    "# 시연을 위한 샘플 텍스트\n",
    "sample_text = \"금통위는 따라서 물가안정과 병행, 경기상황에 유의하는 금리정책을 펼쳐나가기로 했다고 밝혔다.\"\n",
    "print(\"샘플 텍스트:\", sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mecab을 사용한 형태소 분석 및 품사 태깅 예제\n",
    "\n",
    "한국어 NLP에서는 형태소 분석과 품사 태깅이 매우 중요합니다. Mecab을 사용하여 이 두 가지 작업을 동시에 수행할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 분석 및 품사 태깅 결과:\n",
      "금통위: NNG\n",
      "는: JX\n",
      "따라서: MAJ\n",
      "물가: NNG\n",
      "안정: NNG\n",
      "과: JC\n",
      "병행: NNG\n",
      ",: SC\n",
      "경기: NNG\n",
      "상황: NNG\n",
      "에: JKB\n",
      "유의: NNG\n",
      "하: XSV\n",
      "는: ETM\n",
      "금리: NNG\n",
      "정책: NNG\n",
      "을: JKO\n",
      "펼쳐: VV\n",
      "나가: VX\n",
      "기: ETN\n",
      "로: JKB\n",
      "했: VV\n",
      "다고: EC\n",
      "밝혔: VV\n",
      "다: EF\n",
      ".: SF\n",
      "\n",
      "형태소 개수: 26\n",
      "고유 품사 개수: 15\n"
     ]
    }
   ],
   "source": [
    "def analyze_text(text):\n",
    "    \"\"\"Mecab을 사용하여 입력 텍스트의 형태소 분석 및 품사 태깅을 수행합니다.\"\"\"\n",
    "    return mecab.pos(text)\n",
    "\n",
    "\n",
    "# 샘플 텍스트 분석\n",
    "analysis = analyze_text(sample_text)\n",
    "print(\"형태소 분석 및 품사 태깅 결과:\")\n",
    "for morpheme, pos in analysis:\n",
    "    print(f\"{morpheme}: {pos}\")\n",
    "\n",
    "# 형태소와 품사 개수 출력\n",
    "print(f\"\\n형태소 개수: {len(analysis)}\")\n",
    "print(f\"고유 품사 개수: {len({pos for _, pos in analysis})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 한국어 Word2Vec을 사용한 단어 임베딩 시각화\n",
    "\n",
    "단어 임베딩은 의미적 관계를 포착하는 단어의 밀집 벡터 표현입니다. 한국어 텍스트로 학습된 Word2Vec 모델을 사용하여 단어 임베딩을 만들고 시각화해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 Word2Vec 모델이 필요합니다. 실제 사용 시 적절한 모델을 로드하세요.\n"
     ]
    }
   ],
   "source": [
    "def visualize_embeddings(model, words):\n",
    "    \"\"\"t-SNE를 사용하여 단어 임베딩을 시각화합니다.\"\"\"\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if not word_vectors:\n",
    "        print(\"모델 어휘에서 단어를 찾을 수 없습니다.\")\n",
    "        return\n",
    "    word_vectors = np.array(word_vectors)  # numpy 배열로 변환\n",
    "\n",
    "    # 샘플 수에 따라 perplexity 조정\n",
    "    n_samples = word_vectors.shape[0]\n",
    "    perplexity = min(30, n_samples - 1)  # 기본값은 30이지만 n_samples보다 작아야 함\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
    "    embeddings_2d = tsne.fit_transform(word_vectors)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, word in enumerate(words):\n",
    "        if word in model:\n",
    "            x, y = embeddings_2d[i]\n",
    "            plt.scatter(x, y)\n",
    "            plt.annotate(word, (x, y))\n",
    "    plt.title(\"한국어 단어 임베딩 시각화\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 한국어 Word2Vec 모델 로드 (예: 한국어 위키피디아로 학습된 모델)\n",
    "# 실제 사용 시에는 적절한 한국어 Word2Vec 모델을 로드해야 합니다\n",
    "# model = Word2Vec.load(\"path_to_korean_word2vec_model\")\n",
    "\n",
    "# 예제 문장 정의\n",
    "sentences = [\n",
    "    \"경제 성장률이 예상보다 높게 나타났다\",\n",
    "    \"중앙은행이 기준금리를 인상했다\",\n",
    "    \"물가상승률이 목표치를 넘어섰다\",\n",
    "    \"실업률이 전년 대비 소폭 하락했다\",\n",
    "    \"수출 실적이 전월 대비 증가세를 보였다\",\n",
    "]\n",
    "\n",
    "# 문장에서 모든 고유 형태소 가져오기\n",
    "all_morphemes = list(\n",
    "    {morpheme for sentence in sentences for morpheme, _ in mecab.pos(sentence)}\n",
    ")\n",
    "\n",
    "# 모델의 어휘에 있는 형태소만 필터링\n",
    "# words_to_plot = [word for word in all_morphemes if word in model.wv.key_to_index]\n",
    "\n",
    "# 임베딩 시각화\n",
    "# visualize_embeddings(model, words_to_plot)\n",
    "\n",
    "print(\"한국어 Word2Vec 모델이 필요합니다. 실제 사용 시 적절한 모델을 로드하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. OpenAI의 GPT 모델을 사용한 기본 한국어 텍스트 생성 (선택 사항)\n",
    "\n",
    "참고: 이 섹션은 OpenAI API 키가 필요하며 비용이 발생할 수 있습니다. API에 접근할 수 없다면 이 섹션을 건너뛰어도 됩니다.\n",
    "\n",
    "OpenAI의 GPT 모델을 사용하여 한국어 프롬프트를 기반으로 텍스트를 생성해보겠습니다. 이는 한국어 텍스트 생성 작업에서 대규모 언어 모델의 능력을 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어시스턴트: 2023년 한국의 경제 상황은 글로벌 경제의 불확실성과 내부적인 도전 과제가 복합적으로 작용하는 상황입니다. \n",
      "\n",
      "1. **성장률**: 한국 경제는 팬데믹 이후 회복세를 보였으나, 글로벌 경기 둔화와 반도체 산업의 부진 등으로 인해 성장률이 둔화되는 추세입니다. 특히 반도체는 한국 경제의 중요한 축인데, 세계 시장의 수요 감소가 영향을 미치고 있습니다.\n",
      "\n",
      "2. **물가 및 인플레이션**: 물가는 여전히 높은 수준을 유지하고 있으며, 인플레이션 압력이 지속되고 있습니다. 정부는 이러한 물가 상승을 억제하기 위해 금리 인상 등의 통화정책을 시행하고 있습니다.\n",
      "\n",
      "3. **고용 시장**: 고용 시장은 회복세를 보이고 있으나, 고용의 질과 청년 실업 문제는 여전히 해결해야 할 숙제로 남아 있습니다.\n",
      "\n",
      "4. **정책 대응**: 정부는 경제 회복 및 지속 가능한 성장을 위해 다양한 정책을 추진하고 있으며, 특히 친환경 산업과 디지털 전환 분야에 대한 투자에 집중하고 있습니다.\n",
      "\n",
      "전반적으로, 한국 경제는 여러 도전에 직면해 있지만, 구조적인 변화와 혁신을 통해 향후 긍정적인 방향으로 나아갈 것으로 기대됩니다.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# API 키와 모델 이름 설정\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.environ.get(\n",
    "        \"OPENAI_API_KEY\",\n",
    "        \"<환경 변수로 설정되지 않은 경우 OpenAI API 키를 여기에 입력하세요>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# 채팅 완성 생성\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"당신은 한국어에 능통한 도우미입니다. 경제 관련 질문에 답변해주세요.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"한국의 현재 경제 상황에 대해 간단히 설명해주세요.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 어시스턴트의 응답 출력\n",
    "print(f\"어시스턴트: {completion.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "이번 실습 세션에서 우리는 한국어 자연어 처리의 몇 가지 기본 개념과 기술을 탐구했습니다:\n",
    "\n",
    "1. Mecab을 사용하여 한국어 형태소 분석과 품사 태깅을 수행했습니다.\n",
    "2. 한국어 단어 임베딩을 시각화하는 방법을 학습했습니다 (실제 모델 로딩은 필요).\n",
    "3. (선택적으로) GPT 모델을 사용하여 한국어 텍스트 생성을 실험했습니다.\n",
    "\n",
    "이러한 기본 기술들은 더 고급 한국어 NLP 작업과 응용 프로그램의 기초를 형성합니다. 앞으로 몇 주 동안, 우리는 이러한 개념들을 바탕으로 더 정교한 한국어 NLP 방법과 모델을 탐구할 것입니다.\n",
    "\n",
    "## 선택 과제\n",
    "\n",
    "1. 뉴스 기사나 소설 등 다양한 장르의 한국어 텍스트에 대해 형태소 분석과 품사 태깅을 수행해보고, 결과를 비교해보세요.\n",
    "2. 한국어 Word2Vec 모델을 직접 학습시켜보세요. 예를 들어, 한국어 위키피디아 데이터를 사용할 수 있습니다.\n",
    "3. Mecab의 사용자 사전을 활용하여 특정 도메인(예: 경제, 의학)에 특화된 형태소 분석을 수행해보세요.\n",
    "4. 형태소 분석 결과를 사용하여 간단한 한국어 텍스트 분류 모델을 구현해보세요 (예: 뉴스 기사 주제 분류).\n",
    "5. 한국어 감성 분석(Sentiment Analysis) 모델을 구현해보세요. 형태소 분석 결과와 머신러닝 알고리즘을 결합하여 사용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
